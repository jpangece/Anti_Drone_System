{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sanK1pAX4XtW"
      },
      "outputs": [],
      "source": [
        "!pip install transformers -q\n",
        "!pip install datasets -q\n",
        "!pip install accelerate -U -q\n",
        "!pip install wandb -q\n",
        "!wandb login\n",
        "!pip install pretrainedmodels"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import AutoFeatureExtractor, ResNetForImageClassification, TrainingArguments, Trainer, set_seed\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import wandb\n",
        "from datetime import datetime\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "# Set seed for reproducibility\n",
        "seed = 42\n",
        "set_seed(seed)\n",
        "\n",
        "# Load your dataset\n",
        "nasnet_dataset = load_dataset(\"Goorm-AI-04/RCS_Image_Stratified_Train_Test\")\n",
        "test_dataset = nasnet_dataset[\"test\"]\n",
        "\n",
        "# Split dataset into training and evaluation\n",
        "train_dataset, eval_dataset = train_test_split(nasnet_dataset[\"train\"], test_size=0.1, stratify=nasnet_dataset[\"train\"][\"drone_type\"])\n",
        "\n",
        "# Convert datasets to Dataset objects\n",
        "train_dataset = Dataset.from_dict(train_dataset)\n",
        "eval_dataset = Dataset.from_dict(eval_dataset)\n",
        "\n",
        "# Define labels mapping\n",
        "drone_set = set(train_dataset[\"drone_type\"])\n",
        "id2label = {id: label for id, label in enumerate(drone_set)}\n",
        "label2id = {label: id for id, label in id2label.items()}\n",
        "\n",
        "# Define a function to compute metrics\n",
        "def compute_metrics(pred):\n",
        "    logits = pred.predictions\n",
        "    labels = pred.label_ids\n",
        "    preds = np.argmax(logits, axis=1)\n",
        "\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='micro')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "    }\n",
        "\n",
        "# Define a function to add ceiling to an array\n",
        "def ceiling(array, ceiling=1):\n",
        "    array[array > ceiling] = ceiling\n",
        "    return array\n",
        "\n",
        "# Define a function to add floor to an array\n",
        "def floor(array, floor=0):\n",
        "    array[array < floor] = floor\n",
        "    return array\n",
        "\n",
        "# Define a feature extractor\n",
        "feature_extractor = AutoFeatureExtractor.from_pretrained(\"microsoft/resnet-101\")\n",
        "\n",
        "# Define a collate function\n",
        "def collate_fn(examples):\n",
        "    concat = lambda x: np.concatenate([x, x, x], axis=2)\n",
        "    add_noise = lambda x: x + np.random.normal(0, np.sqrt(0.1), x.shape)\n",
        "    images = [floor(ceiling(add_noise(np.array(example[\"rcs_image\"])))) for example in examples]\n",
        "    pixel_values = feature_extractor([concat(np.expand_dims(image, axis=2)) for image in images], do_rescale=False)\n",
        "    pixel_values = torch.tensor(np.array(pixel_values[\"pixel_values\"]))\n",
        "    labels = torch.tensor([example[\"label\"] for example in examples])\n",
        "    return {\"pixel_values\": pixel_values, \"labels\": labels}\n",
        "\n",
        "# Define a training function\n",
        "def run(seed):\n",
        "    if wandb.run is not None:\n",
        "        wandb.finish()\n",
        "\n",
        "    set_seed(seed)\n",
        "\n",
        "    # Load ResNet model\n",
        "    model = ResNetForImageClassification.from_pretrained(\"microsoft/resnet-101\")\n",
        "    param_size = 0\n",
        "    for param in model.parameters():\n",
        "      param_size += param.nelement() * param.element_size()\n",
        "    buffer_size = 0\n",
        "    for buffer in model.buffers():\n",
        "      buffer_size += buffer.nelement() * buffer.element_size()\n",
        "\n",
        "    size_all_mb = (param_size + buffer_size) / 1024**2\n",
        "    print('model size: {:.3f}MB'.format(size_all_mb))\n",
        "\n",
        "    model.classifier = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(2048, 16)\n",
        "    )\n",
        "    model.num_labels = 16\n",
        "    model.id2label = id2label\n",
        "    model.label2id = label2id\n",
        "\n",
        "    # Define training arguments\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir='./drive/MyDrive/RCS/ResNet/results',\n",
        "        num_train_epochs=3,\n",
        "        learning_rate=1e-2,\n",
        "        per_device_train_batch_size=128,\n",
        "        per_device_eval_batch_size=20,\n",
        "        weight_decay=0.01,\n",
        "        logging_dir='./drive/MyDrive/RCS/ResNet/logs',\n",
        "        logging_steps=4,\n",
        "        do_train=True,\n",
        "        do_eval=True,\n",
        "        evaluation_strategy=\"epoch\",\n",
        "        gradient_accumulation_steps=1,\n",
        "        run_name=\"RCS_ResNet101\",\n",
        "        seed=seed,\n",
        "        remove_unused_columns=False,\n",
        "        report_to=\"wandb\",\n",
        "    )\n",
        "\n",
        "    # Initialize WandB\n",
        "    wandb.init(\n",
        "        project=f\"RCS_ResNet101\",\n",
        "        name=f\"{datetime.now().strftime('%b-%d %H:%M')} lr:{training_args.learning_rate:1.0e} batch_size:{training_args.per_device_train_batch_size} epoch:{training_args.num_train_epochs}\",\n",
        "        config=training_args\n",
        "    )\n",
        "\n",
        "    # Define trainer\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=eval_dataset,\n",
        "        compute_metrics=compute_metrics,\n",
        "        data_collator=collate_fn\n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "    trainer.train()\n",
        "\n",
        "    # Calculate metrics on the test dataset\n",
        "    test_results = trainer.predict(test_dataset)\n",
        "\n",
        "    # Calculate additional metrics\n",
        "    test_metrics = compute_metrics(test_results)\n",
        "\n",
        "    # Print or log the eval metrics\n",
        "    print(\"Eval Metrics:\", trainer.evaluate())\n",
        "\n",
        "    # Print or log the test metrics\n",
        "    print(\"Test Metrics:\", test_metrics)\n",
        "\n",
        "    return trainer, model\n",
        "\n",
        "# Run the training and evaluation\n",
        "end_trainer, end_model = run(seed)"
      ],
      "metadata": {
        "id": "i-94Y7Eh4l09"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}